# Machine Learning
This collection of Python Jupyter notebooks are for the exercises of Andrew Ng's excellent [machine learning course on Coursera](https://www.coursera.org/learn/machine-learning). This course is a great way to get started with machine learning, covering the basic concepts and techniques with practical examples done from scratch, from linear regression and logistic regression, to neural networks and recommender systems.

The course is taught in the Octave programming language due to its simplicity, allowing the focus to be on the underlying ideas, and it includes Octave code as the basis of the exercises. After doing the course in Octave, as the instructor intended, I then went back through and translated into Python, my preferred language, as well as I could. These notebooks were originally in a file structure that included the various data sets from the course, but I haven't copied those to this repository as they can all be found in the course itself, so there are a number of lines of code herein that need to be changed for your file structure once you have those requirements.

Hopefully the notebooks are clear enough to see what's going on, but do note that they are offered here without any guarantee of correctness, either in the code or the commentary, which is entirely my own interpretation. Also note that I didn't get the last part of ex8 working and didn't have time to resolve, but most other things worked as intended. There are a number of extra sections and plots where I was simply checking things, and which aren't therefore necessary to just complete the main tasks. But along with notes throughout, these extras may be helpful to better illustrate what's going on. I hope some of the content here is useful for other learners.

## Contents
### ex1
- Exercise 1.2: Linear Regression (dimension-1, power-1, unregularised)
- Exercise 1.3: Linear Regression (dimension-_d_, power-_p<sub>d</sub>_, unregularised)

### ex2
- Exercise 2.1: Logistic Regression (dimension-2, power-1, category-2, unregularised)
- Exercise 2.2: Logistic Regression (dimension-2, power-6, category-2, regularised)

### ex3
- Exercise 3.1: Logistic Regression (dimension-400, power-1, category-10, regularised)
- Exercise 3.2: Neural Network (dimension-400, power-1, category-10, (un)regularised???)

### ex4
- Exercise 4.1: Neural Network (dimension-400, power-1, category-10, regularised)

### ex5
- Exercise 5.1: Linear Regression (dimension-1, power-1, unregularised)
- Exercise 5.2: Learning Curves
- Exercise 5.3: Linear Regression (dimension-1, power-8, unregularised, regularised)

### ex6
- Exercise 6.1: Support Vector Machines (dimension-2, power-various, category-2, regularised)
- Exercise 6.2: Support Vector Machines (dimension-1899, power-1, category-2, regularised)

### ex7
- Exercise 7.1: K-Means Clustering (dimension-2, category-3)
- Exercise 7.1: K-Means Clustering (dimension-3, category-16)
- Exercise 7.2: Principle Component Analysis (PCA) (dimension-2)
- Exercise 7.2: Principle Component Analysis (PCA) (dimension-1024)
- Exercise 7.2: Principle Component Analysis (PCA) (dimension-3)

### ex8
- Exercise 8.1: Anomaly Detection (dimension-2)
- Exercise 8.1: Anomaly Detection (dimension-11)
- Exercise 8.2: Recommender Systems (Collaborative Filtering)
